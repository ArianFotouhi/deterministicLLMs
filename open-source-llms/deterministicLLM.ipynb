{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UVczwKPzsIpG"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6C_fT_iltLsz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deterministic LLM\n"
      ],
      "metadata": {
        "id": "SeRGVkm1sf6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Set seeds\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_id = \"meta-llama/Llama-3.2-1B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Prepare input\n",
        "prompt = \"The theory of relativity is\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "for i in range(2):\n",
        "  # Generate deterministically\n",
        "  outputs = model.generate(\n",
        "      **inputs,\n",
        "\n",
        "      do_sample=False,\n",
        "\n",
        "      #optional: to play around the determinisim parameters\n",
        "      # temperature=0.0,\n",
        "      # top_k=0,\n",
        "      # top_p=1.0,\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  print(f'answer {i+1}')\n",
        "  print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CURu_o3sRHZ",
        "outputId": "b914f2f4-2fa5-4280-b8ce-837a815b64a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer 1\n",
            "The theory of relativity is a theory of physics that describes the relationship between space and time. It was developed by Albert Einstein in\n",
            "answer 2\n",
            "The theory of relativity is a theory of physics that describes the relationship between space and time. It was developed by Albert Einstein in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Deterministic LLM"
      ],
      "metadata": {
        "id": "Htg1dsJGsk7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Set seeds\n",
        "\n",
        "# seed = 42\n",
        "# torch.manual_seed(seed)\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.use_deterministic_algorithms(True)\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_id = \"meta-llama/Llama-3.2-1B\"  # replace with your actual model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Prepare input\n",
        "prompt = \"The theory of relativity is\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "for i in range(2):\n",
        "  # Generate deterministically\n",
        "  outputs = model.generate(\n",
        "      **inputs,\n",
        "\n",
        "      do_sample=True,\n",
        "\n",
        "      #optional: to play around the determinisim parameters\n",
        "      temperature=0.4,\n",
        "      top_k=100,\n",
        "      top_p=0.9,\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  print(f'answer {i+1}')\n",
        "  print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GSvB3SZsj1_",
        "outputId": "227e5b4c-4e9d-4a0c-dc7a-4783364eaf26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer 1\n",
            "The theory of relativity is the most famous theory of physics. It was developed by Albert Einstein in the early 20th century\n",
            "answer 2\n",
            "The theory of relativity is a cornerstone of modern physics. It is a theory that explains the nature of space and time. It\n"
          ]
        }
      ]
    }
  ]
}